{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fe65e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zarr\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from huggingface_hub import HfApi,snapshot_download\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b20291c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 137 files:   0%|          | 0/137 [00:00<?, ?it/s]Cancellation requested; stopping current tasks.\n",
      "Fetching 137 files:   1%|          | 1/137 [00:06<14:42,  6.49s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m      8\u001b[39m allow_patterns = [\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmission\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/*\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Download a specific topic\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m#topic = \"alphasense_front_center\"\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m#allow_patterns = [f\"{mission}/*{topic}*\", f\"{mission}/*.yaml\"]\u001b[39;00m\n\u001b[32m     13\u001b[39m \n\u001b[32m     14\u001b[39m \n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# If this is interuppted during download, simply re-run the block and huggingface_hub will resume the download without re-downloading the already downloaded files.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m hugging_face_data_cache_path = \u001b[43msnapshot_download\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mleggedrobotics/grand_tour_dataset\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_patterns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_patterns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdataset\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/grand_tour/grand_tour_dataset_exploration/venv/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py:114\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[32m    112\u001b[39m     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[34m__name__\u001b[39m, has_token=has_token, kwargs=kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/grand_tour/grand_tour_dataset_exploration/venv/lib/python3.12/site-packages/huggingface_hub/_snapshot_download.py:332\u001b[39m, in \u001b[36msnapshot_download\u001b[39m\u001b[34m(repo_id, repo_type, revision, cache_dir, local_dir, library_name, library_version, user_agent, proxies, etag_timeout, force_download, token, local_files_only, allow_patterns, ignore_patterns, max_workers, tqdm_class, headers, endpoint, local_dir_use_symlinks, resume_download)\u001b[39m\n\u001b[32m    330\u001b[39m         _inner_hf_hub_download(file)\n\u001b[32m    331\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m332\u001b[39m     \u001b[43mthread_map\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    333\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_inner_hf_hub_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    334\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfiltered_repo_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    335\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtqdm_desc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    336\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_workers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    337\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# User can use its own tqdm class or the default one from `huggingface_hub.utils`\u001b[39;49;00m\n\u001b[32m    338\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtqdm_class\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtqdm_class\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mhf_tqdm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    339\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    341\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m local_dir \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    342\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(os.path.realpath(local_dir))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/grand_tour/grand_tour_dataset_exploration/venv/lib/python3.12/site-packages/tqdm/contrib/concurrent.py:69\u001b[39m, in \u001b[36mthread_map\u001b[39m\u001b[34m(fn, *iterables, **tqdm_kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[33;03mEquivalent of `list(map(fn, *iterables))`\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[33;03mdriven by `concurrent.futures.ThreadPoolExecutor`.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     66\u001b[39m \u001b[33;03m    [default: max(32, cpu_count() + 4)].\u001b[39;00m\n\u001b[32m     67\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mconcurrent\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfutures\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ThreadPoolExecutor\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_executor_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mThreadPoolExecutor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43miterables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtqdm_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/grand_tour/grand_tour_dataset_exploration/venv/lib/python3.12/site-packages/tqdm/contrib/concurrent.py:51\u001b[39m, in \u001b[36m_executor_map\u001b[39m\u001b[34m(PoolExecutor, fn, *iterables, **tqdm_kwargs)\u001b[39m\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m ensure_lock(tqdm_class, lock_name=lock_name) \u001b[38;5;28;01mas\u001b[39;00m lk:\n\u001b[32m     48\u001b[39m     \u001b[38;5;66;03m# share lock in case workers are already using `tqdm`\u001b[39;00m\n\u001b[32m     49\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m PoolExecutor(max_workers=max_workers, initializer=tqdm_class.set_lock,\n\u001b[32m     50\u001b[39m                       initargs=(lk,)) \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtqdm_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mex\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43miterables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/grand_tour/grand_tour_dataset_exploration/venv/lib/python3.12/site-packages/tqdm/std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/concurrent/futures/_base.py:619\u001b[39m, in \u001b[36mExecutor.map.<locals>.result_iterator\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    616\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m fs:\n\u001b[32m    617\u001b[39m     \u001b[38;5;66;03m# Careful not to keep a reference to the popped future\u001b[39;00m\n\u001b[32m    618\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m619\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[43m_result_or_cancel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    620\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    621\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m _result_or_cancel(fs.pop(), end_time - time.monotonic())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/concurrent/futures/_base.py:317\u001b[39m, in \u001b[36m_result_or_cancel\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    316\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m317\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfut\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    318\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    319\u001b[39m         fut.cancel()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/concurrent/futures/_base.py:451\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m    449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__get_result()\n\u001b[32m--> \u001b[39m\u001b[32m451\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_condition\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[32m    454\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/threading.py:355\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    353\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[32m    354\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m355\u001b[39m         \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    356\u001b[39m         gotit = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    357\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Specify the mission you want to download.\n",
    "mission = \"2024-10-01-11-29-55\"\n",
    "\n",
    "# Download the full dataset\n",
    "#allow_patterns = [f\"*\"]\n",
    "\n",
    "# Download all data from a single mission\n",
    "allow_patterns = [f\"{mission}/*\"]\n",
    "\n",
    "# Download a specific topic\n",
    "#topic = \"alphasense_front_center\"\n",
    "#allow_patterns = [f\"{mission}/*{topic}*\", f\"{mission}/*.yaml\"]\n",
    "\n",
    "\n",
    "# If this is interuppted during download, simply re-run the block and huggingface_hub will resume the download without re-downloading the already downloaded files.\n",
    "hugging_face_data_cache_path = snapshot_download(repo_id=\"leggedrobotics/grand_tour_dataset\", allow_patterns=allow_patterns, repo_type=\"dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9336639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/rohan/.cache/huggingface/hub/datasets--leggedrobotics--grand_tour_dataset/snapshots/eed9be0dba01495fcc4fe9fd737c9f767a23f8e9'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hugging_face_data_cache_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e63b5c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data will be extracted to: /home/rohan/Desktop/grand_tour/grand_tour_dataset_exploration/missions\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Define the destination directory\n",
    "dataset_folder = Path(\"~/Desktop/grand_tour/grand_tour_dataset_exploration/missions\").expanduser()\n",
    "dataset_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Print for confirmation\n",
    "print(f\"Data will be extracted to: {dataset_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f06018c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rohan/Desktop/grand_tour/grand_tour_dataset_exploration/missions\n",
      "Moved data from /home/rohan/.cache/huggingface/hub/datasets--leggedrobotics--grand_tour_dataset/snapshots/eed9be0dba01495fcc4fe9fd737c9f767a23f8e9 to /home/rohan/Desktop/grand_tour/grand_tour_dataset_exploration/missions !\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import tarfile\n",
    "import re\n",
    "\n",
    "def move_dataset(cache, dataset_folder, allow_patterns=[\"*\"]):\n",
    "\n",
    "    def convert_glob_patterns_to_regex(glob_patterns):\n",
    "        regex_parts = []\n",
    "        for pat in glob_patterns:\n",
    "            # Escape regex special characters except for * and ?\n",
    "            pat = re.escape(pat)\n",
    "            # Convert escaped glob wildcards to regex equivalents\n",
    "            pat = pat.replace(r'\\*', '.*').replace(r'\\?', '.')\n",
    "            # Make sure it matches full paths\n",
    "            regex_parts.append(f\".*{pat}$\")\n",
    "        \n",
    "        # Join with |\n",
    "        combined = \"|\".join(regex_parts)\n",
    "        return re.compile(combined)\n",
    "    \n",
    "    pattern = convert_glob_patterns_to_regex(allow_patterns)\n",
    "    files = [f for f in Path(cache).rglob(\"*\") if pattern.match(str(f))]\n",
    "    tar_files = [f for f in files if f.suffix == \".tar\" ]\n",
    "    \n",
    "    for source_path in tar_files:\n",
    "        dest_path = dataset_folder / source_path.relative_to(cache)\n",
    "        dest_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        try:\n",
    "            with tarfile.open(source_path, \"r\") as tar:\n",
    "                tar.extractall(path=dest_path.parent)\n",
    "        except tarfile.ReadError as e:\n",
    "            print(f\"Error opening or extracting tar file '{source_path}': {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"An unexpected error occurred while processing {source_path}: {e}\")\n",
    "    \n",
    "    other_files = [f for f in files if not f.suffix == \".tar\" and f.is_file()]\n",
    "    for source_path in other_files:\n",
    "        dest_path = dataset_folder / source_path.relative_to(cache)\n",
    "        dest_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        shutil.copy2(source_path,dest_path)\n",
    "\n",
    "    print(f\"Moved data from {cache} to {dataset_folder} !\")\n",
    "\n",
    "print(dataset_folder)\n",
    "move_dataset(hugging_face_data_cache_path, dataset_folder, allow_patterns=allow_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62cf8024",
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting property name enclosed in double quotes: line 2 column 2 (char 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mJSONDecodeError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m mission = \u001b[33m\"\u001b[39m\u001b[33m2024-10-01-11-29-55\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      2\u001b[39m mission_folder = dataset_folder / mission\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m mission_root = \u001b[43mzarr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen_group\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstore\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmission_folder\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mlist\u001b[39m(mission_root.keys())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/grand_tour/grand_tour_dataset_exploration/venv/lib/python3.12/site-packages/zarr/api/synchronous.py:540\u001b[39m, in \u001b[36mopen_group\u001b[39m\u001b[34m(store, mode, cache_attrs, synchronizer, path, chunk_store, storage_options, zarr_version, zarr_format, meta_array, attributes, use_consolidated)\u001b[39m\n\u001b[32m    463\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mopen_group\u001b[39m(\n\u001b[32m    464\u001b[39m     store: StoreLike | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    465\u001b[39m     *,\n\u001b[32m   (...)\u001b[39m\u001b[32m    476\u001b[39m     use_consolidated: \u001b[38;5;28mbool\u001b[39m | \u001b[38;5;28mstr\u001b[39m | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    477\u001b[39m ) -> Group:\n\u001b[32m    478\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Open a group using file-mode-like semantics.\u001b[39;00m\n\u001b[32m    479\u001b[39m \n\u001b[32m    480\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    537\u001b[39m \u001b[33;03m        The new group.\u001b[39;00m\n\u001b[32m    538\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    539\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m Group(\n\u001b[32m--> \u001b[39m\u001b[32m540\u001b[39m         \u001b[43msync\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    541\u001b[39m \u001b[43m            \u001b[49m\u001b[43masync_api\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen_group\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    542\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    543\u001b[39m \u001b[43m                \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    544\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcache_attrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_attrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    545\u001b[39m \u001b[43m                \u001b[49m\u001b[43msynchronizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43msynchronizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    546\u001b[39m \u001b[43m                \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    547\u001b[39m \u001b[43m                \u001b[49m\u001b[43mchunk_store\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunk_store\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    548\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    549\u001b[39m \u001b[43m                \u001b[49m\u001b[43mzarr_version\u001b[49m\u001b[43m=\u001b[49m\u001b[43mzarr_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    550\u001b[39m \u001b[43m                \u001b[49m\u001b[43mzarr_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mzarr_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    551\u001b[39m \u001b[43m                \u001b[49m\u001b[43mmeta_array\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmeta_array\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    552\u001b[39m \u001b[43m                \u001b[49m\u001b[43mattributes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattributes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    553\u001b[39m \u001b[43m                \u001b[49m\u001b[43muse_consolidated\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_consolidated\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    554\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    555\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    556\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/grand_tour/grand_tour_dataset_exploration/venv/lib/python3.12/site-packages/zarr/core/sync.py:163\u001b[39m, in \u001b[36msync\u001b[39m\u001b[34m(coro, loop, timeout)\u001b[39m\n\u001b[32m    160\u001b[39m return_result = \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(finished)).result()\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(return_result, \u001b[38;5;167;01mBaseException\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m163\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m return_result\n\u001b[32m    164\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    165\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m return_result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/grand_tour/grand_tour_dataset_exploration/venv/lib/python3.12/site-packages/zarr/core/sync.py:119\u001b[39m, in \u001b[36m_runner\u001b[39m\u001b[34m(coro)\u001b[39m\n\u001b[32m    114\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    115\u001b[39m \u001b[33;03mAwait a coroutine and return the result of running it. If awaiting the coroutine raises an\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[33;03mexception, the exception will be returned.\u001b[39;00m\n\u001b[32m    117\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m coro\n\u001b[32m    120\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[32m    121\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ex\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/grand_tour/grand_tour_dataset_exploration/venv/lib/python3.12/site-packages/zarr/api/asynchronous.py:857\u001b[39m, in \u001b[36mopen_group\u001b[39m\u001b[34m(store, mode, cache_attrs, synchronizer, path, chunk_store, storage_options, zarr_version, zarr_format, meta_array, attributes, use_consolidated)\u001b[39m\n\u001b[32m    855\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    856\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m _READ_MODES:\n\u001b[32m--> \u001b[39m\u001b[32m857\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m AsyncGroup.open(\n\u001b[32m    858\u001b[39m             store_path, zarr_format=zarr_format, use_consolidated=use_consolidated\n\u001b[32m    859\u001b[39m         )\n\u001b[32m    860\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mKeyError\u001b[39;00m, \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m):\n\u001b[32m    861\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/grand_tour/grand_tour_dataset_exploration/venv/lib/python3.12/site-packages/zarr/core/group.py:595\u001b[39m, in \u001b[36mAsyncGroup.open\u001b[39m\u001b[34m(cls, store, zarr_format, use_consolidated)\u001b[39m\n\u001b[32m    590\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m use_consolidated \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[32m    591\u001b[39m         \u001b[38;5;66;03m# the user explicitly opted out of consolidated_metadata.\u001b[39;00m\n\u001b[32m    592\u001b[39m         \u001b[38;5;66;03m# Discard anything we might have read.\u001b[39;00m\n\u001b[32m    593\u001b[39m         maybe_consolidated_metadata_bytes = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m595\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_from_bytes_v2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    596\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstore_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzgroup_bytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzattrs_bytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaybe_consolidated_metadata_bytes\u001b[49m\n\u001b[32m    597\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    598\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    599\u001b[39m     \u001b[38;5;66;03m# V3 groups are comprised of a zarr.json object\u001b[39;00m\n\u001b[32m    600\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m zarr_json_bytes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/grand_tour/grand_tour_dataset_exploration/venv/lib/python3.12/site-packages/zarr/core/group.py:619\u001b[39m, in \u001b[36mAsyncGroup._from_bytes_v2\u001b[39m\u001b[34m(cls, store_path, zgroup_bytes, zattrs_bytes, consolidated_metadata_bytes)\u001b[39m\n\u001b[32m    610\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m    611\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_from_bytes_v2\u001b[39m(\n\u001b[32m    612\u001b[39m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    617\u001b[39m ) -> AsyncGroup:\n\u001b[32m    618\u001b[39m     \u001b[38;5;66;03m# V2 groups are comprised of a .zgroup and .zattrs objects\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m619\u001b[39m     zgroup = \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mzgroup_bytes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    620\u001b[39m     zattrs = json.loads(zattrs_bytes.to_bytes()) \u001b[38;5;28;01mif\u001b[39;00m zattrs_bytes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[32m    621\u001b[39m     group_metadata = {**zgroup, \u001b[33m\"\u001b[39m\u001b[33mattributes\u001b[39m\u001b[33m\"\u001b[39m: zattrs}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/json/__init__.py:346\u001b[39m, in \u001b[36mloads\u001b[39m\u001b[34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    341\u001b[39m     s = s.decode(detect_encoding(s), \u001b[33m'\u001b[39m\u001b[33msurrogatepass\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    344\u001b[39m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    345\u001b[39m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[32m--> \u001b[39m\u001b[32m346\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    348\u001b[39m     \u001b[38;5;28mcls\u001b[39m = JSONDecoder\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/json/decoder.py:337\u001b[39m, in \u001b[36mJSONDecoder.decode\u001b[39m\u001b[34m(self, s, _w)\u001b[39m\n\u001b[32m    332\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w=WHITESPACE.match):\n\u001b[32m    333\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[32m    334\u001b[39m \u001b[33;03m    containing a JSON document).\u001b[39;00m\n\u001b[32m    335\u001b[39m \n\u001b[32m    336\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m337\u001b[39m     obj, end = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    338\u001b[39m     end = _w(s, end).end()\n\u001b[32m    339\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m end != \u001b[38;5;28mlen\u001b[39m(s):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/json/decoder.py:353\u001b[39m, in \u001b[36mJSONDecoder.raw_decode\u001b[39m\u001b[34m(self, s, idx)\u001b[39m\n\u001b[32m    344\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Decode a JSON document from ``s`` (a ``str`` beginning with\u001b[39;00m\n\u001b[32m    345\u001b[39m \u001b[33;03ma JSON document) and return a 2-tuple of the Python\u001b[39;00m\n\u001b[32m    346\u001b[39m \u001b[33;03mrepresentation and the index in ``s`` where the document ended.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    350\u001b[39m \n\u001b[32m    351\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m353\u001b[39m     obj, end = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscan_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    355\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[33m\"\u001b[39m\u001b[33mExpecting value\u001b[39m\u001b[33m\"\u001b[39m, s, err.value) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mJSONDecodeError\u001b[39m: Expecting property name enclosed in double quotes: line 2 column 2 (char 3)"
     ]
    }
   ],
   "source": [
    "mission = \"2024-10-01-11-29-55\"\n",
    "mission_folder = dataset_folder / mission\n",
    "mission_root = zarr.open_group(store=mission_folder / \"data\", mode='r')\n",
    "list(mission_root.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1477b28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors = [\n",
    "    \"anymal_state_odometry\",\n",
    "    \"anymal_state_state_estimator\",\n",
    "    \"anymal_imu\",\n",
    "    \"anymal_state_actuator\",\n",
    "    \"anymal_command_twist\",\n",
    "    #\"hdr_front\",\n",
    "    #\"hdr_left\",\n",
    "    #\"hdr_right\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ccbf8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_HZ = 50.0\n",
    "DT = 1.0 / TARGET_HZ\n",
    "\n",
    "def _to_np(x):\n",
    "    return np.asarray(x[:]) if hasattr(x, '__getitem__') and not isinstance(x, np.ndarray) else np.asarray(x)\n",
    "\n",
    "def _search_zoh_indices(src_ts, tgt_ts):\n",
    "    \"\"\"\n",
    "    Vectorized zero order hold: for each target time, pick the last src index with src_ts <= tgt\n",
    "    in english: find the index of the last source timestamp that happened at or before that time.\n",
    "    Returns idx array (int) with -1 where no src sample exists yet\n",
    "    \"\"\"\n",
    "    idx = np.searchsorted(src_ts, tgt_ts, side='right') - 1\n",
    "    return idx\n",
    "\n",
    "def _resample_group_zoh(group, tgt_ts, ts_key=\"timestamp\", skip_keys=(\"timestamp\",\"sequence_id\")):\n",
    "    \"\"\"\n",
    "    Resample all fields in a Zarr group to tgt_ts using ZOH.\n",
    "    \"\"\"\n",
    "    out = {}\n",
    "    src_ts = _to_np(group[ts_key])\n",
    "\n",
    "    # Assure ascending timestamps\n",
    "    if not np.all(src_ts[:-1] <= src_ts[1:]):\n",
    "        order = np.argsort(src_ts)\n",
    "        src_ts = src_ts[order]\n",
    "        # Reorder all fields to keep arrays aligned\n",
    "        for key in group.keys():\n",
    "            if key in skip_keys: \n",
    "                continue\n",
    "            arr = _to_np(group[key])\n",
    "            out[key] = arr[order]  # temp store; we’ll overwrite after computing indices\n",
    "        reordered = True\n",
    "    else:\n",
    "        reordered = False\n",
    "\n",
    "    idx = _search_zoh_indices(src_ts, tgt_ts)  # -1 if tgt time is before first src sample\n",
    "    # For each tgt time stamp, find which source timestamp (from og sensor) was the most recent reading that happened <= the tgt time\n",
    "    # --> so idx are the row of the original sensor data to use for each new aligned time step\n",
    "\n",
    "    # Build a safe index for gather; we’ll mask invalids later\n",
    "    safe_idx = idx.copy()\n",
    "    safe_idx[safe_idx < 0] = 0\n",
    "    safe_idx[safe_idx >= len(src_ts)] = len(src_ts) - 1\n",
    "\n",
    "    for key in group.keys():\n",
    "        if key in skip_keys: \n",
    "            continue\n",
    "\n",
    "        arr = _to_np(group[key]) if not (reordered and key in out) else out[key]\n",
    "        # Gather\n",
    "        res = arr[safe_idx]\n",
    "        # Mask times before the first source sample (the -1s from _search_zoh_indices) as NaN \n",
    "        if res.dtype.kind in ('f',):  # floating types: use NaN\n",
    "            res[idx < 0] = np.nan\n",
    "        else:\n",
    "            # For non-floats (ints, bools), you can choose a sentinel; here we keep first value.\n",
    "            pass\n",
    "        out[key] = res\n",
    "\n",
    "    # Always return the resampled timestamps too (the grid)\n",
    "    out[\"timestamp_50hz\"] = tgt_ts\n",
    "    return out\n",
    "\n",
    "def _overlap_window(mission_root, sensors, ts_key=\"timestamp\"):\n",
    "    \"\"\"Compute overlapping [start, end] across sensors to avoid extrapolation beyond last sample.\"\"\"\n",
    "    starts = []\n",
    "    ends = []\n",
    "    for s in sensors:\n",
    "        ts = _to_np(mission_root[s][ts_key])\n",
    "        starts.append(ts[0])\n",
    "        ends.append(ts[-1])\n",
    "    return max(starts), min(ends)\n",
    "\n",
    "def build_50hz_grid(t_start, t_end):\n",
    "    # Inclusive start, inclusive end if it lands exactly; otherwise stops before end\n",
    "    n = int(np.floor((t_end - t_start) * TARGET_HZ)) + 1\n",
    "    return (t_start + np.arange(n) * DT).astype(np.float64)\n",
    "\n",
    "# main entrypoint\n",
    "def align_mission_to_50hz(mission_root, sensors, ts_key=\"timestamp\"):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      {\n",
    "        \"t\": np.ndarray [T],  # 50 Hz grid\n",
    "        \"sensors\": {\n",
    "            sensor_name: { field: np.ndarray[T, ...], \"timestamp_50hz\": np.ndarray[T] }\n",
    "        }\n",
    "      }\n",
    "    \"\"\"\n",
    "    t0, t1 = _overlap_window(mission_root, sensors, ts_key=ts_key)\n",
    "    tgt_ts = build_50hz_grid(t0, t1)\n",
    "\n",
    "    aligned = {}\n",
    "    for s in sensors:\n",
    "        aligned[s] = _resample_group_zoh(mission_root[s], tgt_ts, ts_key=ts_key)\n",
    "\n",
    "    return {\"t\": tgt_ts, \"sensors\": aligned}\n",
    "\n",
    "\n",
    "aligned = align_mission_to_50hz(mission_root, sensors)\n",
    "\n",
    "t = aligned[\"t\"]  # 50 Hz timeline\n",
    "base_lin_vel = aligned[\"sensors\"][\"anymal_state_state_estimator\"][\"twist_lin\"]   \n",
    "imu_ang_vel   = aligned[\"sensors\"][\"anymal_imu\"][\"ang_vel\"]                      \n",
    "cmd_linear    = aligned[\"sensors\"][\"anymal_command_twist\"][\"linear\"]             \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd1f2f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anymal_state_odometry:\n",
      "-->    pose_cov (18228, 6, 6) <class 'numpy.ndarray'>\n",
      "-->    pose_orien (18228, 4) <class 'numpy.ndarray'>\n",
      "-->    pose_pos (18228, 3) <class 'numpy.ndarray'>\n",
      "-->    timestamp_50hz (18228,) <class 'numpy.ndarray'>\n",
      "-->    twist_ang (18228, 3) <class 'numpy.ndarray'>\n",
      "-->    twist_cov (18228, 6, 6) <class 'numpy.ndarray'>\n",
      "-->    twist_lin (18228, 3) <class 'numpy.ndarray'>\n",
      "------------------------------\n",
      "\n",
      "anymal_state_state_estimator:\n",
      "-->    LF_FOOT_contact (18228,) <class 'numpy.ndarray'>\n",
      "-->    LF_FOOT_friction_coef (18228,) <class 'numpy.ndarray'>\n",
      "-->    LF_FOOT_normal (18228, 3) <class 'numpy.ndarray'>\n",
      "-->    LF_FOOT_restitution_coef (18228,) <class 'numpy.ndarray'>\n",
      "-->    LF_FOOT_state (18228,) <class 'numpy.ndarray'>\n",
      "-->    LF_FOOT_wrench_force (18228, 3) <class 'numpy.ndarray'>\n",
      "-->    LF_FOOT_wrench_torque (18228, 3) <class 'numpy.ndarray'>\n",
      "-->    LH_FOOT_contact (18228,) <class 'numpy.ndarray'>\n",
      "-->    LH_FOOT_friction_coef (18228,) <class 'numpy.ndarray'>\n",
      "-->    LH_FOOT_normal (18228, 3) <class 'numpy.ndarray'>\n",
      "-->    LH_FOOT_restitution_coef (18228,) <class 'numpy.ndarray'>\n",
      "-->    LH_FOOT_state (18228,) <class 'numpy.ndarray'>\n",
      "-->    LH_FOOT_wrench_force (18228, 3) <class 'numpy.ndarray'>\n",
      "-->    LH_FOOT_wrench_torque (18228, 3) <class 'numpy.ndarray'>\n",
      "-->    RF_FOOT_contact (18228,) <class 'numpy.ndarray'>\n",
      "-->    RF_FOOT_friction_coef (18228,) <class 'numpy.ndarray'>\n",
      "-->    RF_FOOT_normal (18228, 3) <class 'numpy.ndarray'>\n",
      "-->    RF_FOOT_restitution_coef (18228,) <class 'numpy.ndarray'>\n",
      "-->    RF_FOOT_state (18228,) <class 'numpy.ndarray'>\n",
      "-->    RF_FOOT_wrench_force (18228, 3) <class 'numpy.ndarray'>\n",
      "-->    RF_FOOT_wrench_torque (18228, 3) <class 'numpy.ndarray'>\n",
      "-->    RH_FOOT_contact (18228,) <class 'numpy.ndarray'>\n",
      "-->    RH_FOOT_friction_coef (18228,) <class 'numpy.ndarray'>\n",
      "-->    RH_FOOT_normal (18228, 3) <class 'numpy.ndarray'>\n",
      "-->    RH_FOOT_restitution_coef (18228,) <class 'numpy.ndarray'>\n",
      "-->    RH_FOOT_state (18228,) <class 'numpy.ndarray'>\n",
      "-->    RH_FOOT_wrench_force (18228, 3) <class 'numpy.ndarray'>\n",
      "-->    RH_FOOT_wrench_torque (18228, 3) <class 'numpy.ndarray'>\n",
      "-->    joint_accelerations (18228, 12) <class 'numpy.ndarray'>\n",
      "-->    joint_efforts (18228, 12) <class 'numpy.ndarray'>\n",
      "-->    joint_positions (18228, 12) <class 'numpy.ndarray'>\n",
      "-->    joint_velocities (18228, 12) <class 'numpy.ndarray'>\n",
      "-->    pose_orien (18228, 4) <class 'numpy.ndarray'>\n",
      "-->    pose_pos (18228, 3) <class 'numpy.ndarray'>\n",
      "-->    timestamp_50hz (18228,) <class 'numpy.ndarray'>\n",
      "-->    twist_ang (18228, 3) <class 'numpy.ndarray'>\n",
      "-->    twist_lin (18228, 3) <class 'numpy.ndarray'>\n",
      "------------------------------\n",
      "\n",
      "anymal_imu:\n",
      "-->    ang_vel (18228, 3) <class 'numpy.ndarray'>\n",
      "-->    ang_vel_cov (18228, 3, 3) <class 'numpy.ndarray'>\n",
      "-->    lin_acc (18228, 3) <class 'numpy.ndarray'>\n",
      "-->    lin_acc_cov (18228, 3, 3) <class 'numpy.ndarray'>\n",
      "-->    orien (18228, 4) <class 'numpy.ndarray'>\n",
      "-->    orien_cov (18228, 3, 3) <class 'numpy.ndarray'>\n",
      "-->    timestamp_50hz (18228,) <class 'numpy.ndarray'>\n",
      "------------------------------\n",
      "\n",
      "anymal_state_actuator:\n",
      "-->    00_command_current (18228,) <class 'numpy.ndarray'>\n",
      "-->    00_command_joint_torque (18228,) <class 'numpy.ndarray'>\n",
      "-->    00_command_mode (18228,) <class 'numpy.ndarray'>\n",
      "-->    00_command_pid_gains_d (18228,) <class 'numpy.ndarray'>\n",
      "-->    00_command_pid_gains_i (18228,) <class 'numpy.ndarray'>\n",
      "-->    00_command_pid_gains_p (18228,) <class 'numpy.ndarray'>\n",
      "-->    00_command_position (18228,) <class 'numpy.ndarray'>\n",
      "-->    00_command_velocity (18228,) <class 'numpy.ndarray'>\n",
      "-->    00_state_current (18228,) <class 'numpy.ndarray'>\n",
      "-->    00_state_gear_position (18228,) <class 'numpy.ndarray'>\n",
      "-->    00_state_gear_velocity (18228,) <class 'numpy.ndarray'>\n",
      "-->    00_state_imu_ang_vel (18228, 3) <class 'numpy.ndarray'>\n",
      "-->    00_state_imu_ang_vel_cov (18228, 3, 3) <class 'numpy.ndarray'>\n",
      "-->    00_state_imu_lin_acc (18228, 3) <class 'numpy.ndarray'>\n",
      "-->    00_state_imu_lin_acc_cov (18228, 3, 3) <class 'numpy.ndarray'>\n",
      "-->    00_state_imu_orien (18228, 4) <class 'numpy.ndarray'>\n",
      "-->    00_state_imu_orien_cov (18228, 3, 3) <class 'numpy.ndarray'>\n",
      "-->    00_state_joint_acceleration (18228,) <class 'numpy.ndarray'>\n",
      "-->    00_state_joint_position (18228,) <class 'numpy.ndarray'>\n",
      "-->    00_state_joint_torque (18228,) <class 'numpy.ndarray'>\n",
      "-->    00_state_joint_velocity (18228,) <class 'numpy.ndarray'>\n",
      "-->    00_state_statusword (18228,) <class 'numpy.ndarray'>\n",
      "-->    01_command_current (18228,) <class 'numpy.ndarray'>\n",
      "-->    01_command_joint_torque (18228,) <class 'numpy.ndarray'>\n",
      "-->    01_command_mode (18228,) <class 'numpy.ndarray'>\n",
      "-->    01_command_pid_gains_d (18228,) <class 'numpy.ndarray'>\n",
      "-->    01_command_pid_gains_i (18228,) <class 'numpy.ndarray'>\n",
      "-->    01_command_pid_gains_p (18228,) <class 'numpy.ndarray'>\n",
      "-->    01_command_position (18228,) <class 'numpy.ndarray'>\n",
      "-->    01_command_velocity (18228,) <class 'numpy.ndarray'>\n",
      "-->    01_state_current (18228,) <class 'numpy.ndarray'>\n",
      "-->    01_state_gear_position (18228,) <class 'numpy.ndarray'>\n",
      "-->    01_state_gear_velocity (18228,) <class 'numpy.ndarray'>\n",
      "-->    01_state_imu_ang_vel (18228, 3) <class 'numpy.ndarray'>\n",
      "-->    01_state_imu_ang_vel_cov (18228, 3, 3) <class 'numpy.ndarray'>\n",
      "-->    01_state_imu_lin_acc (18228, 3) <class 'numpy.ndarray'>\n",
      "-->    01_state_imu_lin_acc_cov (18228, 3, 3) <class 'numpy.ndarray'>\n",
      "-->    01_state_imu_orien (18228, 4) <class 'numpy.ndarray'>\n",
      "-->    01_state_imu_orien_cov (18228, 3, 3) <class 'numpy.ndarray'>\n",
      "-->    01_state_joint_acceleration (18228,) <class 'numpy.ndarray'>\n",
      "-->    01_state_joint_position (18228,) <class 'numpy.ndarray'>\n",
      "-->    01_state_joint_torque (18228,) <class 'numpy.ndarray'>\n",
      "-->    01_state_joint_velocity (18228,) <class 'numpy.ndarray'>\n",
      "-->    01_state_statusword (18228,) <class 'numpy.ndarray'>\n",
      "-->    02_command_current (18228,) <class 'numpy.ndarray'>\n",
      "-->    02_command_joint_torque (18228,) <class 'numpy.ndarray'>\n",
      "-->    02_command_mode (18228,) <class 'numpy.ndarray'>\n",
      "-->    02_command_pid_gains_d (18228,) <class 'numpy.ndarray'>\n",
      "-->    02_command_pid_gains_i (18228,) <class 'numpy.ndarray'>\n",
      "-->    02_command_pid_gains_p (18228,) <class 'numpy.ndarray'>\n",
      "-->    02_command_position (18228,) <class 'numpy.ndarray'>\n",
      "-->    02_command_velocity (18228,) <class 'numpy.ndarray'>\n",
      "-->    02_state_current (18228,) <class 'numpy.ndarray'>\n",
      "-->    02_state_gear_position (18228,) <class 'numpy.ndarray'>\n",
      "-->    02_state_gear_velocity (18228,) <class 'numpy.ndarray'>\n",
      "-->    02_state_imu_ang_vel (18228, 3) <class 'numpy.ndarray'>\n",
      "-->    02_state_imu_ang_vel_cov (18228, 3, 3) <class 'numpy.ndarray'>\n",
      "-->    02_state_imu_lin_acc (18228, 3) <class 'numpy.ndarray'>\n",
      "-->    02_state_imu_lin_acc_cov (18228, 3, 3) <class 'numpy.ndarray'>\n",
      "-->    02_state_imu_orien (18228, 4) <class 'numpy.ndarray'>\n",
      "-->    02_state_imu_orien_cov (18228, 3, 3) <class 'numpy.ndarray'>\n",
      "-->    02_state_joint_acceleration (18228,) <class 'numpy.ndarray'>\n",
      "-->    02_state_joint_position (18228,) <class 'numpy.ndarray'>\n",
      "-->    02_state_joint_torque (18228,) <class 'numpy.ndarray'>\n",
      "-->    02_state_joint_velocity (18228,) <class 'numpy.ndarray'>\n",
      "-->    02_state_statusword (18228,) <class 'numpy.ndarray'>\n",
      "-->    03_command_current (18228,) <class 'numpy.ndarray'>\n",
      "-->    03_command_joint_torque (18228,) <class 'numpy.ndarray'>\n",
      "-->    03_command_mode (18228,) <class 'numpy.ndarray'>\n",
      "-->    03_command_pid_gains_d (18228,) <class 'numpy.ndarray'>\n",
      "-->    03_command_pid_gains_i (18228,) <class 'numpy.ndarray'>\n",
      "-->    03_command_pid_gains_p (18228,) <class 'numpy.ndarray'>\n",
      "-->    03_command_position (18228,) <class 'numpy.ndarray'>\n",
      "-->    03_command_velocity (18228,) <class 'numpy.ndarray'>\n",
      "-->    03_state_current (18228,) <class 'numpy.ndarray'>\n",
      "-->    03_state_gear_position (18228,) <class 'numpy.ndarray'>\n",
      "-->    03_state_gear_velocity (18228,) <class 'numpy.ndarray'>\n",
      "-->    03_state_imu_ang_vel (18228, 3) <class 'numpy.ndarray'>\n",
      "-->    03_state_imu_ang_vel_cov (18228, 3, 3) <class 'numpy.ndarray'>\n",
      "-->    03_state_imu_lin_acc (18228, 3) <class 'numpy.ndarray'>\n",
      "-->    03_state_imu_lin_acc_cov (18228, 3, 3) <class 'numpy.ndarray'>\n",
      "-->    03_state_imu_orien (18228, 4) <class 'numpy.ndarray'>\n",
      "-->    03_state_imu_orien_cov (18228, 3, 3) <class 'numpy.ndarray'>\n",
      "-->    03_state_joint_acceleration (18228,) <class 'numpy.ndarray'>\n",
      "-->    03_state_joint_position (18228,) <class 'numpy.ndarray'>\n",
      "-->    03_state_joint_torque (18228,) <class 'numpy.ndarray'>\n",
      "-->    03_state_joint_velocity (18228,) <class 'numpy.ndarray'>\n",
      "-->    03_state_statusword (18228,) <class 'numpy.ndarray'>\n",
      "-->    04_command_current (18228,) <class 'numpy.ndarray'>\n",
      "-->    04_command_joint_torque (18228,) <class 'numpy.ndarray'>\n",
      "-->    04_command_mode (18228,) <class 'numpy.ndarray'>\n",
      "-->    04_command_pid_gains_d (18228,) <class 'numpy.ndarray'>\n",
      "-->    04_command_pid_gains_i (18228,) <class 'numpy.ndarray'>\n",
      "-->    04_command_pid_gains_p (18228,) <class 'numpy.ndarray'>\n",
      "-->    04_command_position (18228,) <class 'numpy.ndarray'>\n",
      "-->    04_command_velocity (18228,) <class 'numpy.ndarray'>\n",
      "-->    04_state_current (18228,) <class 'numpy.ndarray'>\n",
      "-->    04_state_gear_position (18228,) <class 'numpy.ndarray'>\n",
      "-->    04_state_gear_velocity (18228,) <class 'numpy.ndarray'>\n",
      "-->    04_state_imu_ang_vel (18228, 3) <class 'numpy.ndarray'>\n",
      "-->    04_state_imu_ang_vel_cov (18228, 3, 3) <class 'numpy.ndarray'>\n",
      "-->    04_state_imu_lin_acc (18228, 3) <class 'numpy.ndarray'>\n",
      "-->    04_state_imu_lin_acc_cov (18228, 3, 3) <class 'numpy.ndarray'>\n",
      "-->    04_state_imu_orien (18228, 4) <class 'numpy.ndarray'>\n",
      "-->    04_state_imu_orien_cov (18228, 3, 3) <class 'numpy.ndarray'>\n",
      "-->    04_state_joint_acceleration (18228,) <class 'numpy.ndarray'>\n",
      "-->    04_state_joint_position (18228,) <class 'numpy.ndarray'>\n",
      "-->    04_state_joint_torque (18228,) <class 'numpy.ndarray'>\n",
      "-->    04_state_joint_velocity (18228,) <class 'numpy.ndarray'>\n",
      "-->    04_state_statusword (18228,) <class 'numpy.ndarray'>\n",
      "-->    05_command_current (18228,) <class 'numpy.ndarray'>\n",
      "-->    05_command_joint_torque (18228,) <class 'numpy.ndarray'>\n",
      "-->    05_command_mode (18228,) <class 'numpy.ndarray'>\n",
      "-->    05_command_pid_gains_d (18228,) <class 'numpy.ndarray'>\n",
      "-->    05_command_pid_gains_i (18228,) <class 'numpy.ndarray'>\n",
      "-->    05_command_pid_gains_p (18228,) <class 'numpy.ndarray'>\n",
      "-->    05_command_position (18228,) <class 'numpy.ndarray'>\n",
      "-->    05_command_velocity (18228,) <class 'numpy.ndarray'>\n",
      "-->    05_state_current (18228,) <class 'numpy.ndarray'>\n",
      "-->    05_state_gear_position (18228,) <class 'numpy.ndarray'>\n",
      "-->    05_state_gear_velocity (18228,) <class 'numpy.ndarray'>\n",
      "-->    05_state_imu_ang_vel (18228, 3) <class 'numpy.ndarray'>\n",
      "-->    05_state_imu_ang_vel_cov (18228, 3, 3) <class 'numpy.ndarray'>\n",
      "-->    05_state_imu_lin_acc (18228, 3) <class 'numpy.ndarray'>\n",
      "-->    05_state_imu_lin_acc_cov (18228, 3, 3) <class 'numpy.ndarray'>\n",
      "-->    05_state_imu_orien (18228, 4) <class 'numpy.ndarray'>\n",
      "-->    05_state_imu_orien_cov (18228, 3, 3) <class 'numpy.ndarray'>\n",
      "-->    05_state_joint_acceleration (18228,) <class 'numpy.ndarray'>\n",
      "-->    05_state_joint_position (18228,) <class 'numpy.ndarray'>\n",
      "-->    05_state_joint_torque (18228,) <class 'numpy.ndarray'>\n",
      "-->    05_state_joint_velocity (18228,) <class 'numpy.ndarray'>\n",
      "-->    05_state_statusword (18228,) <class 'numpy.ndarray'>\n",
      "-->    06_command_current (18228,) <class 'numpy.ndarray'>\n",
      "-->    06_command_joint_torque (18228,) <class 'numpy.ndarray'>\n",
      "-->    06_command_mode (18228,) <class 'numpy.ndarray'>\n",
      "-->    06_command_pid_gains_d (18228,) <class 'numpy.ndarray'>\n",
      "-->    06_command_pid_gains_i (18228,) <class 'numpy.ndarray'>\n",
      "-->    06_command_pid_gains_p (18228,) <class 'numpy.ndarray'>\n",
      "-->    06_command_position (18228,) <class 'numpy.ndarray'>\n",
      "-->    06_command_velocity (18228,) <class 'numpy.ndarray'>\n",
      "-->    06_state_current (18228,) <class 'numpy.ndarray'>\n",
      "-->    06_state_gear_position (18228,) <class 'numpy.ndarray'>\n",
      "-->    06_state_gear_velocity (18228,) <class 'numpy.ndarray'>\n",
      "-->    06_state_imu_ang_vel (18228, 3) <class 'numpy.ndarray'>\n",
      "-->    06_state_imu_ang_vel_cov (18228, 3, 3) <class 'numpy.ndarray'>\n",
      "-->    06_state_imu_lin_acc (18228, 3) <class 'numpy.ndarray'>\n",
      "-->    06_state_imu_lin_acc_cov (18228, 3, 3) <class 'numpy.ndarray'>\n",
      "-->    06_state_imu_orien (18228, 4) <class 'numpy.ndarray'>\n",
      "-->    06_state_imu_orien_cov (18228, 3, 3) <class 'numpy.ndarray'>\n",
      "-->    06_state_joint_acceleration (18228,) <class 'numpy.ndarray'>\n",
      "-->    06_state_joint_position (18228,) <class 'numpy.ndarray'>\n",
      "-->    06_state_joint_torque (18228,) <class 'numpy.ndarray'>\n",
      "-->    06_state_joint_velocity (18228,) <class 'numpy.ndarray'>\n",
      "-->    06_state_statusword (18228,) <class 'numpy.ndarray'>\n",
      "-->    07_command_current (18228,) <class 'numpy.ndarray'>\n",
      "-->    07_command_joint_torque (18228,) <class 'numpy.ndarray'>\n",
      "-->    07_command_mode (18228,) <class 'numpy.ndarray'>\n",
      "-->    07_command_pid_gains_d (18228,) <class 'numpy.ndarray'>\n",
      "-->    07_command_pid_gains_i (18228,) <class 'numpy.ndarray'>\n",
      "-->    07_command_pid_gains_p (18228,) <class 'numpy.ndarray'>\n",
      "-->    07_command_position (18228,) <class 'numpy.ndarray'>\n",
      "-->    07_command_velocity (18228,) <class 'numpy.ndarray'>\n",
      "-->    07_state_current (18228,) <class 'numpy.ndarray'>\n",
      "-->    07_state_gear_position (18228,) <class 'numpy.ndarray'>\n",
      "-->    07_state_gear_velocity (18228,) <class 'numpy.ndarray'>\n",
      "-->    07_state_imu_ang_vel (18228, 3) <class 'numpy.ndarray'>\n",
      "-->    07_state_imu_ang_vel_cov (18228, 3, 3) <class 'numpy.ndarray'>\n",
      "-->    07_state_imu_lin_acc (18228, 3) <class 'numpy.ndarray'>\n",
      "-->    07_state_imu_lin_acc_cov (18228, 3, 3) <class 'numpy.ndarray'>\n",
      "-->    07_state_imu_orien (18228, 4) <class 'numpy.ndarray'>\n",
      "-->    07_state_imu_orien_cov (18228, 3, 3) <class 'numpy.ndarray'>\n",
      "-->    07_state_joint_acceleration (18228,) <class 'numpy.ndarray'>\n",
      "-->    07_state_joint_position (18228,) <class 'numpy.ndarray'>\n",
      "-->    07_state_joint_torque (18228,) <class 'numpy.ndarray'>\n",
      "-->    07_state_joint_velocity (18228,) <class 'numpy.ndarray'>\n",
      "-->    07_state_statusword (18228,) <class 'numpy.ndarray'>\n",
      "-->    08_command_current (18228,) <class 'numpy.ndarray'>\n",
      "-->    08_command_joint_torque (18228,) <class 'numpy.ndarray'>\n",
      "-->    08_command_mode (18228,) <class 'numpy.ndarray'>\n",
      "-->    08_command_pid_gains_d (18228,) <class 'numpy.ndarray'>\n",
      "-->    08_command_pid_gains_i (18228,) <class 'numpy.ndarray'>\n",
      "-->    08_command_pid_gains_p (18228,) <class 'numpy.ndarray'>\n",
      "-->    08_command_position (18228,) <class 'numpy.ndarray'>\n",
      "-->    08_command_velocity (18228,) <class 'numpy.ndarray'>\n",
      "-->    08_state_current (18228,) <class 'numpy.ndarray'>\n",
      "-->    08_state_gear_position (18228,) <class 'numpy.ndarray'>\n",
      "-->    08_state_gear_velocity (18228,) <class 'numpy.ndarray'>\n",
      "-->    08_state_imu_ang_vel (18228, 3) <class 'numpy.ndarray'>\n",
      "-->    08_state_imu_ang_vel_cov (18228, 3, 3) <class 'numpy.ndarray'>\n",
      "-->    08_state_imu_lin_acc (18228, 3) <class 'numpy.ndarray'>\n",
      "-->    08_state_imu_lin_acc_cov (18228, 3, 3) <class 'numpy.ndarray'>\n",
      "-->    08_state_imu_orien (18228, 4) <class 'numpy.ndarray'>\n",
      "-->    08_state_imu_orien_cov (18228, 3, 3) <class 'numpy.ndarray'>\n",
      "-->    08_state_joint_acceleration (18228,) <class 'numpy.ndarray'>\n",
      "-->    08_state_joint_position (18228,) <class 'numpy.ndarray'>\n",
      "-->    08_state_joint_torque (18228,) <class 'numpy.ndarray'>\n",
      "-->    08_state_joint_velocity (18228,) <class 'numpy.ndarray'>\n",
      "-->    08_state_statusword (18228,) <class 'numpy.ndarray'>\n",
      "-->    09_command_current (18228,) <class 'numpy.ndarray'>\n",
      "-->    09_command_joint_torque (18228,) <class 'numpy.ndarray'>\n",
      "-->    09_command_mode (18228,) <class 'numpy.ndarray'>\n",
      "-->    09_command_pid_gains_d (18228,) <class 'numpy.ndarray'>\n",
      "-->    09_command_pid_gains_i (18228,) <class 'numpy.ndarray'>\n",
      "-->    09_command_pid_gains_p (18228,) <class 'numpy.ndarray'>\n",
      "-->    09_command_position (18228,) <class 'numpy.ndarray'>\n",
      "-->    09_command_velocity (18228,) <class 'numpy.ndarray'>\n",
      "-->    09_state_current (18228,) <class 'numpy.ndarray'>\n",
      "-->    09_state_gear_position (18228,) <class 'numpy.ndarray'>\n",
      "-->    09_state_gear_velocity (18228,) <class 'numpy.ndarray'>\n",
      "-->    09_state_imu_ang_vel (18228, 3) <class 'numpy.ndarray'>\n",
      "-->    09_state_imu_ang_vel_cov (18228, 3, 3) <class 'numpy.ndarray'>\n",
      "-->    09_state_imu_lin_acc (18228, 3) <class 'numpy.ndarray'>\n",
      "-->    09_state_imu_lin_acc_cov (18228, 3, 3) <class 'numpy.ndarray'>\n",
      "-->    09_state_imu_orien (18228, 4) <class 'numpy.ndarray'>\n",
      "-->    09_state_imu_orien_cov (18228, 3, 3) <class 'numpy.ndarray'>\n",
      "-->    09_state_joint_acceleration (18228,) <class 'numpy.ndarray'>\n",
      "-->    09_state_joint_position (18228,) <class 'numpy.ndarray'>\n",
      "-->    09_state_joint_torque (18228,) <class 'numpy.ndarray'>\n",
      "-->    09_state_joint_velocity (18228,) <class 'numpy.ndarray'>\n",
      "-->    09_state_statusword (18228,) <class 'numpy.ndarray'>\n",
      "-->    10_command_current (18228,) <class 'numpy.ndarray'>\n",
      "-->    10_command_joint_torque (18228,) <class 'numpy.ndarray'>\n",
      "-->    10_command_mode (18228,) <class 'numpy.ndarray'>\n",
      "-->    10_command_pid_gains_d (18228,) <class 'numpy.ndarray'>\n",
      "-->    10_command_pid_gains_i (18228,) <class 'numpy.ndarray'>\n",
      "-->    10_command_pid_gains_p (18228,) <class 'numpy.ndarray'>\n",
      "-->    10_command_position (18228,) <class 'numpy.ndarray'>\n",
      "-->    10_command_velocity (18228,) <class 'numpy.ndarray'>\n",
      "-->    10_state_current (18228,) <class 'numpy.ndarray'>\n",
      "-->    10_state_gear_position (18228,) <class 'numpy.ndarray'>\n",
      "-->    10_state_gear_velocity (18228,) <class 'numpy.ndarray'>\n",
      "-->    10_state_imu_ang_vel (18228, 3) <class 'numpy.ndarray'>\n",
      "-->    10_state_imu_ang_vel_cov (18228, 3, 3) <class 'numpy.ndarray'>\n",
      "-->    10_state_imu_lin_acc (18228, 3) <class 'numpy.ndarray'>\n",
      "-->    10_state_imu_lin_acc_cov (18228, 3, 3) <class 'numpy.ndarray'>\n",
      "-->    10_state_imu_orien (18228, 4) <class 'numpy.ndarray'>\n",
      "-->    10_state_imu_orien_cov (18228, 3, 3) <class 'numpy.ndarray'>\n",
      "-->    10_state_joint_acceleration (18228,) <class 'numpy.ndarray'>\n",
      "-->    10_state_joint_position (18228,) <class 'numpy.ndarray'>\n",
      "-->    10_state_joint_torque (18228,) <class 'numpy.ndarray'>\n",
      "-->    10_state_joint_velocity (18228,) <class 'numpy.ndarray'>\n",
      "-->    10_state_statusword (18228,) <class 'numpy.ndarray'>\n",
      "-->    11_command_current (18228,) <class 'numpy.ndarray'>\n",
      "-->    11_command_joint_torque (18228,) <class 'numpy.ndarray'>\n",
      "-->    11_command_mode (18228,) <class 'numpy.ndarray'>\n",
      "-->    11_command_pid_gains_d (18228,) <class 'numpy.ndarray'>\n",
      "-->    11_command_pid_gains_i (18228,) <class 'numpy.ndarray'>\n",
      "-->    11_command_pid_gains_p (18228,) <class 'numpy.ndarray'>\n",
      "-->    11_command_position (18228,) <class 'numpy.ndarray'>\n",
      "-->    11_command_velocity (18228,) <class 'numpy.ndarray'>\n",
      "-->    11_state_current (18228,) <class 'numpy.ndarray'>\n",
      "-->    11_state_gear_position (18228,) <class 'numpy.ndarray'>\n",
      "-->    11_state_gear_velocity (18228,) <class 'numpy.ndarray'>\n",
      "-->    11_state_imu_ang_vel (18228, 3) <class 'numpy.ndarray'>\n",
      "-->    11_state_imu_ang_vel_cov (18228, 3, 3) <class 'numpy.ndarray'>\n",
      "-->    11_state_imu_lin_acc (18228, 3) <class 'numpy.ndarray'>\n",
      "-->    11_state_imu_lin_acc_cov (18228, 3, 3) <class 'numpy.ndarray'>\n",
      "-->    11_state_imu_orien (18228, 4) <class 'numpy.ndarray'>\n",
      "-->    11_state_imu_orien_cov (18228, 3, 3) <class 'numpy.ndarray'>\n",
      "-->    11_state_joint_acceleration (18228,) <class 'numpy.ndarray'>\n",
      "-->    11_state_joint_position (18228,) <class 'numpy.ndarray'>\n",
      "-->    11_state_joint_torque (18228,) <class 'numpy.ndarray'>\n",
      "-->    11_state_joint_velocity (18228,) <class 'numpy.ndarray'>\n",
      "-->    11_state_statusword (18228,) <class 'numpy.ndarray'>\n",
      "-->    timestamp_50hz (18228,) <class 'numpy.ndarray'>\n",
      "------------------------------\n",
      "\n",
      "anymal_command_twist:\n",
      "-->    angular (18228, 3) <class 'numpy.ndarray'>\n",
      "-->    linear (18228, 3) <class 'numpy.ndarray'>\n",
      "-->    timestamp_50hz (18228,) <class 'numpy.ndarray'>\n",
      "------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sensor in sensors:\n",
    "    print(f\"{sensor}:\")\n",
    "    keys = list(aligned[\"sensors\"][sensor].keys())\n",
    "    keys.sort()\n",
    "    for key in keys:\n",
    "        print(f\"-->    {key} {aligned[\"sensors\"][sensor][key].shape} {type(aligned[\"sensors\"][sensor][key])}\")\n",
    "    print(f\"------------------------------\\n\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "82a02ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_axis_params(value, axis_idx):\n",
    "    axis = np.zeros(3)\n",
    "    axis[axis_idx] = value\n",
    "    return axis\n",
    "\n",
    "def quat_rotate_inverse(q, v):\n",
    "    \"\"\"\n",
    "    Rotate vector(s) v by the inverse of quaternion(s) q.\n",
    "    q: (..., 4) array [x, y, z, w]\n",
    "    v: (..., 3) array\n",
    "    returns: rotated v in same shape\n",
    "    \"\"\"\n",
    "    q = np.asarray(q)\n",
    "    v = np.asarray(v)\n",
    "\n",
    "    q_vec = q[..., :3]         # (x, y, z)\n",
    "    q_w = q[..., 3]            # w\n",
    "    t = 2.0 * np.cross(q_vec, v)\n",
    "    return v - q_w[..., None] * t + np.cross(q_vec, t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b726074c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from reward import compute_rewards_offline\n",
    "def build_offline_dataset(data, episode_len_s=20, hz=50):\n",
    "    \"\"\"Convert aligned ANYmal sensor data into offline RL dataset.\"\"\"\n",
    "\n",
    "    est = data[\"sensors\"][\"anymal_state_state_estimator\"]\n",
    "    act = data[\"sensors\"][\"anymal_state_actuator\"]\n",
    "    cmd = data[\"sensors\"][\"anymal_command_twist\"]\n",
    "    imu = data[\"sensors\"][\"anymal_imu\"]\n",
    "\n",
    "    up_axis_idx = 2 # 2 for z, 1 for y -> adapt gravity accordingly\n",
    "    gravity_vec = get_axis_params(-1., up_axis_idx)\n",
    "    base_quat =  imu[\"orien\"] # assumes quaternion that rotates body --> world \n",
    "    projected_gravity = quat_rotate_inverse(base_quat, gravity_vec) # (T,4)\n",
    "\n",
    "    base_lin_vel = est[\"twist_lin\"]          # (T, 3)\n",
    "    base_ang_vel = est[\"twist_ang\"]          # (T, 3)\n",
    "    joint_pos = est[\"joint_positions\"]       # (T, 12)\n",
    "    joint_vel = est[\"joint_velocities\"]      # (T, 12)\n",
    "    cmd_lin = cmd[\"linear\"]                  # (T, 3)\n",
    "    cmd_ang = cmd[\"angular\"]                 # (T, 3)\n",
    "\n",
    "    act_keys = [f\"{i:02d}_command_position\" for i in range(12)]\n",
    "    actions = np.stack([act[k] for k in act_keys], axis=-1)   # (T, 12)\n",
    "\n",
    "    prev_actions = np.zeros_like(actions)\n",
    "    prev_actions[1:] = actions[:-1]\n",
    "\n",
    "    obs = np.concatenate([\n",
    "        base_lin_vel,\n",
    "        base_ang_vel,\n",
    "        projected_gravity,\n",
    "        joint_pos,\n",
    "        joint_vel,\n",
    "        prev_actions,       \n",
    "        cmd_lin,\n",
    "        cmd_ang,\n",
    "    ], axis=-1)  # (T, obs_dim)\n",
    "    \n",
    "    rews = compute_rewards_offline(\n",
    "        base_ang_vel,\n",
    "        base_lin_vel,\n",
    "        prev_actions,\n",
    "        actions,\n",
    "        joint_vel,\n",
    "        est[\"LF_FOOT_contact\"],\n",
    "        est[\"LH_FOOT_contact\"],\n",
    "        est[\"RF_FOOT_contact\"],\n",
    "        est[\"RH_FOOT_contact\"],\n",
    "        cmd_lin,\n",
    "        cmd_ang,\n",
    "        est[\"joint_efforts\"],\n",
    "        len(obs)\n",
    "    )\n",
    "\n",
    "    # Shift for next_observations \n",
    "    observations = obs[:-1]\n",
    "    next_observations = obs[1:]\n",
    "    actions = actions[:-1]\n",
    "    rewards = rews[:-1]\n",
    "\n",
    "    # Terminals every 20s (20s * 50hz = 1000 steps)\n",
    "    T = len(observations)\n",
    "    episode_len = int(episode_len_s * hz)\n",
    "    terminals = np.zeros(T, dtype=bool)\n",
    "    terminals[np.arange(episode_len - 1, T, episode_len)] = True\n",
    "\n",
    "\n",
    "    # offline dataset \n",
    "    dataset = dict(\n",
    "        observations=observations,\n",
    "        actions=actions,\n",
    "        next_observations=next_observations,\n",
    "        rewards=rewards,\n",
    "        terminals=terminals,\n",
    "    )\n",
    "\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3639f6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = build_offline_dataset(aligned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "de6f305e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observations: <class 'numpy.ndarray'> (18227, 51)\n",
      "actions: <class 'numpy.ndarray'> (18227, 12)\n",
      "next_observations: <class 'numpy.ndarray'> (18227, 51)\n",
      "rewards: <class 'numpy.ndarray'> (18227,)\n",
      "terminals: <class 'numpy.ndarray'> (18227,)\n"
     ]
    }
   ],
   "source": [
    "for k in list(dataset.keys()):\n",
    "    print(f\"{k}: {type(dataset[k])} {dataset[k].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8e550473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "26.53067552820117\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([27.44218748, 27.05541286, 26.39754375, 26.51982278, 24.91035863,\n",
       "       24.27332467, 26.3357035 , 26.53067553, 27.70199123, 26.7212877 ,\n",
       "       26.60569158, 26.46818968, 26.61520911, 26.70020568, 26.95783483,\n",
       "       26.43130929, 26.16244311, 26.72840684,  6.05985623])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def episode_returns(rewards, terminals):\n",
    "    episode_sums = []\n",
    "    current_sum = 0.0\n",
    "\n",
    "    for r, done in zip(rewards, terminals):\n",
    "        current_sum += r\n",
    "        if done:\n",
    "            episode_sums.append(current_sum)\n",
    "            current_sum = 0.0\n",
    "\n",
    "    if not terminals[-1]:\n",
    "        episode_sums.append(current_sum)\n",
    "\n",
    "    return np.array(episode_sums)\n",
    "\n",
    "ep_ret = episode_returns(dataset[\"rewards\"], dataset[\"terminals\"])\n",
    "print(len(ep_ret))\n",
    "print(np.median(ep_ret))\n",
    "ep_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ce67527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 47 missions\n"
     ]
    }
   ],
   "source": [
    "# TEST\n",
    "dataset_folder = Path(\"~/Desktop/grand_tour/grand_tour_dataset_exploration/missions\").expanduser()\n",
    "missions = [d.name for d in dataset_folder.iterdir() if d.is_dir()]\n",
    "print(f\"Total {len(missions)} missions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1da6bcc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligning 2024-11-15-14-14-12 (1/47)\n",
      "Aligning 2024-12-09-09-34-43 (2/47)\n",
      "Aligning 2024-12-09-09-41-46 (3/47)\n",
      "Aligning 2024-11-03-13-51-43 (4/47)\n",
      "Aligning 2024-11-03-07-52-45 (5/47)\n",
      "Aligning 2024-11-15-14-43-52 (6/47)\n",
      "Aligning 2024-10-01-12-00-49 (7/47)\n",
      "Aligning 2024-11-15-11-18-14 (8/47)\n",
      "Aligning 2024-11-11-12-42-47 (9/47)\n",
      "Aligning 2024-11-02-17-43-10 (10/47)\n",
      "Aligning 2024-11-14-11-17-02 (11/47)\n",
      "Aligning 2024-11-11-14-29-44 (12/47)\n",
      "Aligning 2024-11-18-12-05-01 (13/47)\n",
      "Aligning 2024-11-03-07-57-34 (14/47)\n",
      "Aligning 2024-11-18-13-22-14 (15/47)\n",
      "Aligning 2024-12-09-11-53-11 (16/47)\n",
      "Aligning 2024-11-04-16-05-00 (17/47)\n",
      "Aligning 2024-11-11-12-07-40 (18/47)\n",
      "Aligning 2024-11-03-08-17-23 (19/47)\n",
      "Aligning 2024-11-25-16-36-19 (20/47)\n",
      "Aligning 2024-11-18-15-46-05 (21/47)\n",
      "Aligning 2024-11-18-16-59-23 (22/47)\n",
      "Aligning 2024-11-04-12-55-59 (23/47)\n",
      "Aligning 2024-11-18-13-48-19 (24/47)\n",
      "Aligning 2024-11-18-17-31-36 (25/47)\n",
      "Aligning 2024-11-14-16-04-09 (26/47)\n",
      "Aligning 2024-11-18-17-13-09 (27/47)\n",
      "Aligning 2024-11-15-10-16-35 (28/47)\n",
      "Aligning 2024-11-14-13-45-37 (29/47)\n",
      "Aligning 2024-12-03-13-15-38 (30/47)\n",
      "Aligning 2024-11-02-21-12-51 (31/47)\n",
      "Aligning 2024-11-14-15-22-43 (32/47)\n",
      "Aligning 2024-11-14-12-01-26 (33/47)\n",
      "Aligning 2024-11-25-14-57-08 (34/47)\n",
      "Aligning 2024-10-01-11-47-44 (35/47)\n",
      "Aligning 2024-11-11-16-14-23 (36/47)\n",
      "Aligning 2024-11-02-17-10-25 (37/47)\n",
      "Aligning 2024-11-04-10-57-34 (38/47)\n",
      "Aligning 2024-12-03-13-26-40 (39/47)\n",
      "Aligning 2024-12-09-11-28-28 (40/47)\n",
      "Aligning 2024-11-03-13-59-54 (41/47)\n",
      "Aligning 2024-11-04-13-07-13 (42/47)\n",
      "Aligning 2024-11-14-14-36-02 (43/47)\n",
      "Aligning 2024-11-15-16-41-14 (44/47)\n",
      "Aligning 2024-11-15-12-06-03 (45/47)\n",
      "Aligning 2024-11-02-17-18-32 (46/47)\n",
      "Aligning 2024-11-15-11-37-15 (47/47)\n"
     ]
    }
   ],
   "source": [
    "idx = 1\n",
    "for mission in missions:\n",
    "    print(f\"Aligning {mission} ({idx}/{len(missions)})\")\n",
    "    mission_folder = dataset_folder / mission\n",
    "    mission_root = zarr.open_group(store=mission_folder / \"data\", mode='r')\n",
    "    idx+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9a627e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
